{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Making Predictions with the BERT Model\n",
        "This notebook uses a fine-tuned BERT model to make sentiment predictions on input text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import pandas as pd\n",
        "\n",
        "def predict(text):\n",
        "    tokenizer = BertTokenizer.from_pretrained('../models/bert_model')\n",
        "    model = BertForSequenceClassification.from_pretrained('../models/bert_model')\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    return \"positive\" if prediction == 1 else \"negative\"\n",
        "\n",
        "def main(text):\n",
        "    sentiment = predict(text)\n",
        "    print(f\"Sentiment: {sentiment}\")\n",
        "\n",
        "    # Save prediction to results/predictions.csv\n",
        "    results = pd.DataFrame({'text': [text], 'sentiment': [sentiment]})\n",
        "    results.to_csv('../results/predictions.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    text = \"I love using BERT for NLP tasks!\"\n",
        "    main(text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
